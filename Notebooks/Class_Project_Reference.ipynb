{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Project Reference\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What analysis are you going to do?\n",
    "\n",
    "Please run your study idea by Jeremy or Jin before progressing.\n",
    "\n",
    "A few potentially interesting ones may include:\n",
    "\n",
    "Scary VS non-scary \n",
    "Loud VS quiet \n",
    "People VS no-people\n",
    "Anything your imagination comes up with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing your GLM\n",
    "\n",
    "Before we can make our GLM in SPM we need to create onsets. Once you have cleared your research question with Jin or Jeremy go ahead and start coding the movie as was done in the excel file available in the Class Project folder on canvas. The movie clips are also in that folder.\n",
    "\n",
    "\n",
    "\n",
    "You want to record the time that each event or block of interest starts and when it stops so we can calculate onsets and durations.\n",
    "\n",
    "Remember that when we convert from seconds to TR's we want to subtract 1 TR since we start counting at TR 0.\n",
    "\n",
    "Our study had 456 TR's in each run, the 1st TR of the first run counts as TR 0, the last TR of the first run as 455 and the first TR of the 2nd run counts as TR 456.\n",
    "\n",
    "For each condition you have save your onsets as conditionname.txt and conditionname_dur.txt.\n",
    "\n",
    "# FTP\n",
    "\n",
    "Next we need to move the onsets we to the server. FTP stands for File Transfer Protocol.\n",
    "\n",
    "Download Cyberduck here: https://cyberduck.io/?l=en for mac or pc. \n",
    "\n",
    "Install Cyberduck and click `Add Connection` \n",
    "\n",
    "Click on the pull-down menu where it says FTP with the hard drive symbol next to it and select SFTP.\n",
    "\n",
    "Under server put your server: (hera or eros).dartmouth.edu\n",
    "\n",
    "Enter your username (pbs60x) and password then click connect.\n",
    "\n",
    "This is now showing you your file listing in your home directory on your server.\n",
    "\n",
    "Make a new folder by clicking on the `Action` button then `New Folder`.\n",
    "\n",
    "Label the folder YOURCOMPARISON_ONSETS.\n",
    "\n",
    "Drag and drop your onsets into your new folder. \n",
    "\n",
    "Now you can reconnect to your VNC session and continue from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM\n",
    "\n",
    "Once you have your onsets created you want to build the GLM for each subject. \n",
    "\n",
    "First lets generate/load the nuissance regressors for a subject. You will need to do this separately for each subject as you want to run their GLM.\n",
    "\n",
    "Building your nuisance regressors (linear trends for each run, binary run regressor, the constant is generated automatically)\n",
    "In matlab type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runregressors=[linspace(0,1,456)' zeros(456,1) ones(456,1); zeros(456,1) linspace(0,1,456)' zeros(456,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use this for each subject in combination with the subjects motion and the onsets you made to create your GLM.\n",
    "\n",
    "I would suggest opening gedit text editor (Click the Foot, Accessories, gedit) and copying this command in to a new document so you can use it multiple times.\n",
    "\n",
    "<img src=\"Images/CA_runregressors.png\"></img>\n",
    "\n",
    "Remember, you only want to run the GLM for subjects that you think should be included in the analysis. Be prepared to say why you decided that subjects should be included or excluded in the analysis in the write-up.\n",
    "\n",
    "Next lets load in the a subject's motion regressors and combine the nuisance regressors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load('/afs/dbic.dartmouth.edu/usr/PBS60/DATA/prep/epi_norm/s001/rp_aepi_r01.txt')\n",
    "load('/afs/dbic.dartmouth.edu/usr/PBS60/DATA/prep/epi_norm/s001/rp_aepi_r02.txt')\n",
    "s001_regressors=[[rp_aepi_r01;rp_aepi_r02] runregressors]\n",
    "whos\n",
    "cd ~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see at least 4 varaibles, importantly one named for each of the files you loaded, runregressors and your subject's combined regressors file. `whos` shows you what variables are in the matlab workspace and cd ~ brings you back to your home directory.\n",
    "\n",
    "Do this for each subject that you are including in the analysis. When you are done make sure you have regressors for all of the subjects you want to run using whos and save these files so we don't need to remake them later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('all_subject_regressors.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have these variables saved as a .mat file lets output each \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir('~/SUBJECT_REGRESSORS')\n",
    "cd('~/SUBJECT_REGRESSORS')\n",
    "csvwrite('s001_regressors.txt',s001_regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do this for each of the subjects, replacing s001 with each subjects' #.\n",
    "\n",
    "Next we need to make some directories to store the GLM files for each subject you are using. Below replace YOURANALYSIS with something descriptive like SCARY_NOTSCARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~\n",
    "mkdir ./GLM_YOURANALYSIS\n",
    "cd GLM_YOURANALYSIS\n",
    "mkdir ./s001\n",
    "mkdir ./s002\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue until you have made directories for each subject.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GLM: Specify 1st-level\n",
    "Now return to the SPM GUI.  \n",
    "To run a GLM on the first subject we need to chose `Specify 1st-level` from the SPM menu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chose output directory of GLM\n",
    "\n",
    "You want to select the subject's GLM directory you created\n",
    "\n",
    "Once you do this it should say something like .../PBS60/pbs60a/GLM_YOURANALYSIS/s001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Units for design\n",
    "\n",
    "We can specify our study design in second OR in TRs. We are going to use TR's here. Click `Timing parameters` > `Units for design` and select `Scans`.\n",
    "\n",
    "Next select `Interscan interval`, click button `Specify` and type in 2.5 since our scans were acquired every 2.5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading our preprocessed files\n",
    "\n",
    "Our class data was preprocessed and is good to go for us to make a 1st-level (single subject) GLM.\n",
    "\n",
    "We are going to be using 4D .nii files for this part. These files contain data from multiple TRs (scans) and make data management easier.\n",
    "\n",
    "Click `Data & Design` then `Scans`\n",
    "\n",
    "Navigate to /afs/dbic.dartmouth.edu/usr/PBS60/DATA/prep/epi_norm/s001/  \n",
    "Type swuaepi* in filter  \n",
    "Below filter type 1:456  \n",
    "<img src=\"Images/Lab_03_DataDesign_Scans.png\"></img>\n",
    "\n",
    "This should show 912 files, 456 from each run. \n",
    "\n",
    "The top file should be highlighted or click on the top most file, then\n",
    "scroll to the bottom, hold down shift and click the last one which should move all of them to the Selected menu then click `Done`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditions\n",
    "\n",
    "This tab is where we setup how many experimental conditions we have. We can have as many conditions as we want.\n",
    "\n",
    "Click on `Conditions`, `New Condition`, `Name` then `Specify`. You want to type in YOURCONDITION1 or something similar like that so you can remember that we are marking when the movie is on in this condition. Do this again for as many conditions as you have.\n",
    "\n",
    "Lets use the onsets you created. The onsets are values that tell the computer/model what times  the events we care about started.\n",
    "Next click on `Onsets` then `Specify`\n",
    "\n",
    "Since we already loaded the movieon.mat file that contains our onsets we are can load them by just naming the matlab variable. Check to see that it looks correct by typing `whos` which will show you the loaded variables AND their size. If you have 10 events/durations then the variables should be of size 10x1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuisance regressors\n",
    "\n",
    "Click Multiple regressors, Specify and Navigate to /afs/dbic.dartmouth.edu/usr/PBS60/ `yourdirectory` /SUBJECT_REGRESSORS/ and select this subject's _regressors.txt file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving GLM and creating model\n",
    "\n",
    "Before you try to run your GLM you should save it. \n",
    "\n",
    "Click `File` then `Save Batch`\n",
    "\n",
    "Save it as GLM_s001_YOURCONDITIONS.mat or something descriptive of your analysis.\n",
    "\n",
    "Once you have saved you can click play (green arrow).\n",
    "\n",
    "# Estimating model\n",
    "\n",
    "Next we need to estimate the model. This means we want to apply the results of the GLM we estimated above to the brain data.  \n",
    "\n",
    "Click `Estimate` from the SPM menu. This only asks us for one thing... the SPM.mat file within the subjects GLM directory.\n",
    "\n",
    "Select the SPM.mat file in your GLM folder then click the green play button and wait for a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast of interest\n",
    "\n",
    "Go back to the SPM menu and click `Results`\n",
    "\n",
    "Select your SPM.mat file\n",
    "\n",
    "Click `Define contrast`, name it based on your condition, ie MOVIEON or scaryVSnonscary etc.\n",
    "\n",
    "We want to identify regions that are more active when the movie is on so we want to weight the first column and ignore the others. \n",
    "\n",
    "Click `t-contrast` since we want a directional contrast. \n",
    "\n",
    "Click in the contrast weights vector and enter #'s that appropriately match your comparison of interest. Feel free to ask for help at this point.\n",
    "\n",
    "Click `Submit`. \n",
    "\n",
    "Doing this weights our columns of interest by the factors entered above and treats all of the other columns as nuisance regressors. \n",
    "\n",
    "Click `Done`\n",
    "\n",
    "A different window will ask you if you want to do any masking... click none\n",
    "\n",
    "Title for comparison: yourcomparison\n",
    "\n",
    "You don't need to do any adjustment for p-value, click through the defaults for p-value and extent.\n",
    "\n",
    "This will create con_0001.nii and spmT_0001.nii files in the GLM directory for the current subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Repeat for each subject\n",
    "\n",
    "Repeat the steps above for each subject, substituting the new subject number for s001. When you are all done you should have GLM folder for each subject with files in them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Effects (RFX)\n",
    "\n",
    "Once you have run your GLM on each subject then you can run RFX on the resulting files to identify areas that were consistently activated across individuals. Below replace YOURANALYSIS with something descriptive like SCARY_NOTSCARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~\n",
    "mkdir ./RFX_YOURANALYSIS\n",
    "cd('RFX_YOURANALYSIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Click `Specify 2nd-level`\n",
    "\n",
    "This will open batch editor. Lets select our current directory as the output directory from the left menu, \".\"\n",
    "\n",
    "Under `Design` chose `One-sample t-test` then under `Scans` click `Specify`\n",
    "\n",
    "Select the con_001.nii files for each subject that you want to include in your random effects model. \n",
    "\n",
    "Next from the `Batch Editor` menubar select `SPM`, `Stats`, `Model Estimation`\n",
    "This will create a new module below `Factorial design`\n",
    "Click on the `Model Estimation` module then `Dependancy` and click `OK` in the new window that pops up. \n",
    "\n",
    "Next from the `Batch Editor` menubar select `SPM`, `Stats`, `Contrast Manager`\n",
    "This will create a new module below `Model Estimation`\n",
    "Click on the `Contrast Manager` module then `Dependancy`, select `Model Estimation` and click `OK` in the new window that pops up. \n",
    "\n",
    "Next within the `Contrast Manager` module click on `Contrast Sessions` then `New: T-contrast`.\n",
    "Edit name to be `MOVIEON`, change the weights vector to be `1`\n",
    "\n",
    "Click File, Save Batch and save as RFX_YOURANALYSIS.mat in your home directory.\n",
    "\n",
    "Click play then inspect your results (spmT file) in your RFX_YOURANALYSIS folder in xjview once matlab says its done processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing and exporting your data\n",
    "\n",
    "View the results of your RFX analysis in xjview. To do this load the spmT_0001 file in your random effects folder.\n",
    "<img src=\"Images/CA_xjview.png\"></img>\n",
    "Click `Done` and you should see your image open with a default p value of 0.001 and cluster size of 5. The p-value listed here is the p-value for each voxel and the cluster size is the minimum number of voxels that have to be next to each other to show up in our image. \n",
    "\n",
    "Below the top right window pane select single T1\n",
    "<img src=\"Images/CA_xjviewT1.png\"></img>\n",
    "\n",
    "\n",
    "Multiple comparisons here\n",
    "\n",
    "\n",
    "<img src=\"Images/CA_xjviewThresholds.png\"></img>\n",
    "\n",
    "\n",
    "\n",
    "# Visualization\n",
    "\n",
    "Once you have identified a significace threshold/cluster size that you are going to use you can click on Render V (should say View but is often obscured). This will make a simple surface representation of your data. You can screen shot this from your computer.\n",
    "\n",
    "Mac: Click back to your desktop or finder, then press Command, Shift 4 at the same time. Click and drag to take a screen shot of the views you want. \n",
    "PC: https://support.microsoft.com/en-us/help/13776/windows-use-snipping-tool-to-capture-screenshots\n",
    "\n",
    "Next you can make some publication quality slice views by click `Slice View`, which is directly above render. You can select how many columns, rows and how far between each slice you want to view. You can also view the slices in different orientations. You can take screen shots of the images the same way as above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General notes for writeup\n",
    "\n",
    "Image Acquisition:\n",
    "\n",
    "3T Siemens Prisma fMRI scanner equipped with a 32-channel head coil. \n",
    "\n",
    "We collected a scout, anatomical scan, and two functional scans.  \n",
    "\n",
    "Anatomical scan parameters (MPRAGE)\n",
    "Voxel size : 1 x 1 x 1 mm \n",
    "Slices: 192 saggital slices\n",
    "TE : 2.32 ms \n",
    "TR: 2300 ms\n",
    "Flip Angle: 8 degrees\n",
    "Matrix size: 256 x 256 \n",
    "FOV = 240mm x 240mm\n",
    "Acceleration: Grappa 2 \n",
    "\n",
    "Functional scan parameters\n",
    "Voxel size : 3 x 3 x 3 mm (3mm isotropic)\n",
    "Slices: 40 transversal slices\n",
    "TE: 35 ms\n",
    "TR : 2500 ms\n",
    "Flip Angle: 79 degrees\n",
    "Matrix size: 80 x 80 \n",
    "Field of view 240mm x 240 mm  \n",
    "Acceleration: Grappa 2 \n",
    "456 measurements \n",
    "\n",
    "\n",
    "Image Preprocessing:\n",
    "\n",
    "All imaging preprocessing and subsequent analyses were conducted in SPM12 (Wellcome Department of Cognitive Neurology) in conjunction with a suite of tools for preprocessing and analysis (https://github.com/ddwagner/SPM12w). Functional images were slice-time-corrected and realigned to account for temporal differences in slice acquisition and head motion, respectively. Resulting volumes were spatially normalized to the ICBM 152 template brain (Montreal Neurological Institute) and spatially smoothed using an 6-mm (FWHM) Gaussian kernel.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
